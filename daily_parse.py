#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–æ–≤.
–î–æ–±–∞–≤–ª—è–µ—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –æ—Ç–∑—ã–≤—ã.
"""

import os
import sys
import logging
from datetime import datetime, timedelta
import time
from typing import List, Dict, Set
from sqlalchemy import create_engine, select, func
from sqlalchemy.orm import sessionmaker
from dotenv import load_dotenv

from parser import TwoGISReviewsParser
from database import Review, Branch, ParseReport
from parse_sandyq_tary import load_branches_from_csv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
log_dir = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(log_dir, exist_ok=True)

log_file = os.path.join(log_dir, f'daily_parse_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
DATABASE_URL = os.getenv('DATABASE_URL')
if not DATABASE_URL:
    logger.error("DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    sys.exit(1)

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


def get_existing_review_ids(session, branch_id: str) -> Set[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ ID —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è —Ñ–∏–ª–∏–∞–ª–∞"""
    existing_ids = session.execute(
        select(Review.review_id).where(Review.branch_id == branch_id)
    ).scalars().all()
    return set(existing_ids)


def get_latest_review_date(session, branch_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ—Ç–∑—ã–≤–∞ –¥–ª—è —Ñ–∏–ª–∏–∞–ª–∞"""
    latest_date = session.execute(
        select(func.max(Review.date_created)).where(Review.branch_id == branch_id)
    ).scalar()
    return latest_date


def save_new_reviews_to_db(session, reviews: List[Dict], branch_id: str, branch_name: str, existing_ids: Set[str]) -> int:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
    new_count = 0
    
    for review_data in reviews:
        review_id = review_data.get('id') or review_data.get('review_id')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–∑—ã–≤—ã –±–µ–∑ ID
        if not review_id:
            logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω –æ—Ç–∑—ã–≤ –±–µ–∑ ID: {review_data.get('text', '')[:50]}...")
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ—Ç–∑—ã–≤—ã
        if review_id in existing_ids:
            continue
            
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã
            date_str = review_data.get('date_created', '')
            date_created = None
            if date_str:
                try:
                    date_created = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                except:
                    try:
                        date_created = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
                    except:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É: {date_str}")
            
            review = Review(
                review_id=review_id,
                branch_id=branch_id,
                branch_name=branch_name,
                user_name=review_data.get('user', {}).get('name', '–ê–Ω–æ–Ω–∏–º'),
                rating=int(review_data.get('rating', 0)),
                text=review_data.get('text', ''),
                date_created=date_created,
                is_verified=review_data.get('verified', False),
                likes_count=review_data.get('likes_count', 0),
                comments_count=review_data.get('comments_count', 0),
                photos_count=review_data.get('photos_count', 0),
                photos_urls=review_data.get('photos_urls', [])
            )
            
            session.add(review)
            new_count += 1
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –æ—Ç–∑—ã–≤–∞ {review_id}: {e}")
            continue
    
    return new_count


def parse_branch_incrementally(parser: TwoGISReviewsParser, branch: Dict, session) -> Dict:
    """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∏–ª–∏–∞–ª–∞"""
    branch_name = branch['name']
    branch_id = branch['id_2gis']
    
    logger.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∏–ª–∏–∞–ª–∞: {branch_name} (ID: {branch_id})")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ—Ç–∑—ã–≤—ã
    existing_ids = get_existing_review_ids(session, branch_id)
    latest_date = get_latest_review_date(session, branch_id)
    
    logger.info(f"  üìä –í –±–∞–∑–µ —É–∂–µ –µ—Å—Ç—å {len(existing_ids)} –æ—Ç–∑—ã–≤–æ–≤")
    if latest_date:
        logger.info(f"  üìÖ –ü–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–∑—ã–≤ –æ—Ç: {latest_date}")
    
    try:
        # –ü–∞—Ä—Å–∏–º –≤—Å–µ –æ—Ç–∑—ã–≤—ã (API 2GIS –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–∞—Ç–µ)
        all_reviews = parser.parse_all_reviews(branch_id, branch_name)
        
        if not all_reviews:
            logger.warning(f"  ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–∑—ã–≤—ã –¥–ª—è {branch_name}")
            return {
                'branch_name': branch_name,
                'branch_id': branch_id,
                'status': 'failed',
                'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–∑—ã–≤—ã',
                'total_reviews': 0,
                'new_reviews': 0
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –æ—Ç–∑—ã–≤—ã
        new_count = save_new_reviews_to_db(session, all_reviews, branch_id, branch_name, existing_ids)
        
        logger.info(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {new_count} –∏–∑ {len(all_reviews)}")
        
        return {
            'branch_name': branch_name,
            'branch_id': branch_id,
            'status': 'success',
            'total_reviews': len(all_reviews),
            'new_reviews': new_count,
            'existing_reviews': len(existing_ids)
        }
        
    except Exception as e:
        logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {branch_name}: {e}")
        return {
            'branch_name': branch_name,
            'branch_id': branch_id,
            'status': 'failed',
            'error': str(e),
            'total_reviews': 0,
            'new_reviews': 0
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    start_time = datetime.now()
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–æ–≤")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Ñ–∏–ª–∏–∞–ª–æ–≤
    csv_path = "data/sandyq_tary_branches.csv"
    if not os.path.exists(csv_path):
        logger.error(f"‚ùå –§–∞–π–ª {csv_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        sys.exit(1)
    
    branches = load_branches_from_csv(csv_path)
    if not branches:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∏–ª–∏–∞–ª–æ–≤")
        sys.exit(1)
    
    logger.info(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(branches)} —Ñ–∏–ª–∏–∞–ª–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
    parser = TwoGISReviewsParser()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –ë–î
    session = SessionLocal()
    
    try:
        # –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–∂–¥–æ–≥–æ —Ñ–∏–ª–∏–∞–ª–∞
        results = []
        total_new_reviews = 0
        successful_branches = 0
        
        for i, branch in enumerate(branches, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–ª–∏–∞–ª–∞ {i}/{len(branches)}")
            
            result = parse_branch_incrementally(parser, branch, session)
            results.append(result)
            
            if result['status'] == 'success':
                successful_branches += 1
                total_new_reviews += result['new_reviews']
            
            # –ö–æ–º–º–∏—Ç –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ñ–∏–ª–∏–∞–ª–∞
            session.commit()
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i < len(branches):
                time.sleep(2)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –ø–∞—Ä—Å–∏–Ω–≥–µ
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        report = ParseReport(
            parse_date=start_time,
            total_branches=len(branches),
            successful_branches=successful_branches,
            failed_branches=len(branches) - successful_branches,
            total_reviews=sum(r.get('total_reviews', 0) for r in results),
            new_reviews=total_new_reviews,
            duration_seconds=duration,
            errors=str([r for r in results if r['status'] == 'failed'])
        )
        
        session.add(report)
        session.commit()
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info(f"\n{'='*60}")
        logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"  ‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
        logger.info(f"  üè¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∏–ª–∏–∞–ª–æ–≤: {successful_branches}/{len(branches)}")
        logger.info(f"  üìù –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {total_new_reviews}")
        logger.info(f"  ‚ùå –§–∏–ª–∏–∞–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏: {len(branches) - successful_branches}")
        
        # –í—ã–≤–æ–¥ —Ñ–∏–ª–∏–∞–ª–æ–≤ —Å –Ω–æ–≤—ã–º–∏ –æ—Ç–∑—ã–≤–∞–º–∏
        branches_with_new = [r for r in results if r.get('new_reviews', 0) > 0]
        if branches_with_new:
            logger.info("\nüìå –§–∏–ª–∏–∞–ª—ã —Å –Ω–æ–≤—ã–º–∏ –æ—Ç–∑—ã–≤–∞–º–∏:")
            for r in branches_with_new:
                logger.info(f"  - {r['branch_name']}: +{r['new_reviews']} –æ—Ç–∑—ã–≤–æ–≤")
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ –æ—Ç–∑—ã–≤—ã
        if total_new_reviews > 0:
            logger.info("\nüì± –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ –æ—á–µ—Ä–µ–¥—å...")
            try:
                from telegram_notifications_queue import send_notifications_for_new_reviews
                send_notifications_for_new_reviews()
                logger.info("‚úÖ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –æ—á–µ—Ä–µ–¥—å")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ –æ—á–µ—Ä–µ–¥—å: {e}")
        else:
            logger.info("\nüì± –ù–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –Ω–µ—Ç, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        session.rollback()
        sys.exit(1)
    finally:
        session.close()
        logger.info("\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω")


if __name__ == "__main__":
    main()